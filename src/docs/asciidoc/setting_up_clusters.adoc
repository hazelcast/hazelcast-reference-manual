
[[setting-up-clusters]]
== Setting Up Clusters

This chapter describes Hazelcast clusters and the methods
cluster members and native clients use to form a Hazelcast cluster.

[[discovery-mechanisms]]
=== Discovery Mechanisms

A Hazelcast cluster is a network of cluster members that run Hazelcast.
Cluster members  automatically join together to form a cluster. This automatic
joining takes place with various discovery mechanisms that the cluster members
use to find each other.

Please note that, after a cluster is formed, communication between cluster members
is always via TCP/IP, regardless of the discovery mechanism used.

Hazelcast uses the following discovery mechanisms.

NOTE: See the link:https://hazelcast.com/resources/hazelcast-deployment-operations-guide/[Hazelcast IMDG Deployment and Operations Guide^]
for advices on the best discovery mechanism to use.

[[auto-detection]]
==== Auto Detection

By default, Hazelcast tries to automatically detect the applicable discovery mechanism based on the runtime environment.

Note that using Auto Detection is not recommended for production. Note also that if Hazelcast finds no applicable
discovery mechanism, then it falls back to <<multicast, Multicast>>.

See the <<discovering-members-auto-detection, Discovering Members by Auto Detection section>> for more details.

[[tcp]]
==== TCP

You can configure Hazelcast to be a full TCP/IP cluster. See the
<<discovering-members-by-tcp, Discovering Members by TCP section>> for configuration details.

[[multicast]]
==== Multicast

With this mechanism, Hazelcast allows cluster members to find each other
using the multicast communication. See the
<<discovering-members-by-multicast, Discovering Members by Multicast section>>.

If you prefer to use this mechanism, make sure that your network is secure.
Since multicast packets are being broadcasted, any member with the appropriate cluster name
can join the cluster, so you have less control on the cluster.

Note also that if User Datagram Protocol (UDP) is blocked, as it is for most of the production environments,
discovering with multicast does not work.

[[aws-cloud-discovery]]
==== AWS Cloud Discovery

Hazelcast supports EC2/ECS auto-discovery. It is useful when you
do not want to provide or you cannot provide the list of possible
IP addresses. See the <<hazelcast-cloud-discovery-plugins-aws, Cloud Discovery Plugins: Hazelcast AWS section>>.

[[azure-cloud-discovery]]
==== Azure Cloud Discovery

Hazelcast offers a discovery strategy for your Hazelcast applications
running on Azure. See the <<hazelcast-cloud-discovery-plugins-azure, Cloud Discovery Plugins: Hazelcast Azure section>>.

[[gcp-cloud-discovery]]
==== GCP Cloud Discovery

Hazelcast supports discovering members in the link:https://cloud.google.com/compute/[GCP Compute Engine^]
environment. You can easily configure Hazelcast members discovery, WAN replication,
and Hazelcast Client to work seamlessly on the native GCP VM Instances.
This discovery feature is provided as a Hazelcast plugin.
See the <<hazelcast-cloud-discovery-plugins-gcp, Cloud Discovery Plugins: Hazelcast GCP section>>.

[[kubernetes-cloud-discovery]]
==== Kubernetes Cloud Discovery

Hazelcast provides Kubernetes discovery mechanism that looks for IP addresses of members.
See the <<hazelcast-cloud-discovery-plugins-kubernetes, Cloud Discovery Plugins: Hazelcast Kubernetes section>>.

[[eureka-cloud-discovery]]
==== Eureka Cloud Discovery

Hazelcast supports the Eureka V1 discovery.
See the <<hazelcast-cloud-discovery-plugins-eureka, Cloud Discovery Plugins: Hazelcast Eureka section>>.

[[zookeeper-cloud-discovery]]
==== Zookeeper Cloud Discovery

This discovery mechanism provides a service based discovery strategy by using
Apache Curator to communicate with your Zookeeper server.
See the <<hazelcast-cloud-discovery-plugins-zookeeper, Cloud Discovery Plugins: Hazelcast Zookeeper section>>.

[[hazelcast-for-pcf]]
==== Hazelcast for Tanzu VMware

Using a clickable Hazelcast Tile for VMWare (former Pivotal Cloud Foundry), you can
deploy your Hazelcast cluster on PCF. This feature is provided as a Hazelcast
plugin.
See the <<deploying-on-pivotal-cloud-foundry, Deploying in VMware Tanzu section>>.

[[discovering-members-auto-detection]]
=== Discovering Members by Auto Detection

Auto Detection is a good way to start playing with Hazelcast. It tries to automatically detect the appropriate
discovery plugin and apply it to your Hazelcast configuration. Assuming you have `hazelcast-all`
on your classpath and your runtime is Kubernetes, Hazelcast automatically applies
the <<kubernetes-cloud-discovery, Kubernetes discovery mechanism>>.

Below is a table with minimal requirements for each environment.

.Environment Requirements
[cols="2,5a"]
|===

|Environment|Requirements

|<<hazelcast-cloud-discovery-plugins-aws, AWS>>
|AWS EC2 requires the following points:

* Security Group with the port 5701 open
* IAM role with the `ec2:DescribeInstances` permission attached to the EC2 Instance

|<<hazelcast-cloud-discovery-plugins-azure, Azure>>
|Azure requires having Azure managed identity with the `READ` role attached to your Azure Virtual Machine.

|<<hazelcast-cloud-discovery-plugins-gcp, GCP>>
|GCP requires having Cloud API (at minimum Read Only to Compute Engine API) access attached to your VM Instance.

|<<hazelcast-cloud-discovery-plugins-kubernetes, Kubernetes>>
| Kubernetes requires applying the
link:https://raw.githubusercontent.com/hazelcast/hazelcast-kubernetes/master/rbac.yaml[RBAC permissions^].

|===

[[discovering-members-by-tcp]]
=== Discovering Members by TCP

If multicast is not the preferred way of discovery for your environment,
then you can configure Hazelcast to be a full TCP/IP cluster. When you configure
Hazelcast to discover members by TCP/IP, you must list all or a subset of the members'
host names and/or IP addresses as cluster members. You do not have to list all of these
cluster members, but at least one of the listed members has to be active in the cluster
when a new member joins.

To configure your Hazelcast to be a full TCP/IP cluster, set the following
configuration elements. See the <<tcp-ip-element, tcp-ip element section>> for the
full descriptions of the TCP/IP discovery configuration elements.

* Set the `enabled` attribute of the `tcp-ip` element to `true`.
* Provide your `member` elements within the `tcp-ip` element.

The following is an example declarative configuration.

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <join>
            <tcp-ip enabled="true">
                <member>machine1</member>
                <member>machine2</member>
                <member>machine3:5799</member>
                <member>192.168.1.0-7</member>
                <member>192.168.1.21</member>
            </tcp-ip>
        </join>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    join:
      tcp-ip:
        enabled: true
        member-list:
          - machine1
          - machine2
          - machine3:5799
          - 192.168.1.0-7
          - 192.168.1.21
----

As shown above, you can provide IP addresses or host names for `member` elements.
You can also give a range of IP addresses, such as `192.168.1.0-7`.

Instead of providing members line-by-line as shown above, you also have the option
to use the `members` element and write comma-separated IP addresses, as shown below.

`<members>192.168.1.0-7,192.168.1.21</members>`

If you do not provide ports for the members, Hazelcast automatically tries the
ports 5701, 5702 and so on.

By default, Hazelcast binds to all local network interfaces to accept incoming
traffic. You can change this behavior using the system property `hazelcast.socket.bind.any`.
If you set this property to `false`, Hazelcast uses the interfaces specified in the `interfaces`
element (see the <<interfaces, Interfaces Configuration section>>). If no interfaces are
provided, then it tries to resolve one interface to bind from the `member` elements.

[[discovering-members-by-multicast]]
=== Discovering Members by Multicast

With the multicast auto-discovery mechanism, Hazelcast allows cluster members to find
each other using multicast communication. The cluster members do not need to know the
concrete addresses of the other members, as they just multicast to all the other members
for listening. Whether multicast is possible or allowed depends on your environment.

To set your Hazelcast to multicast auto-discovery, set the following configuration
elements. See the <<multicast-element, multicast element section>> for the full
description of the multicast discovery configuration elements.

* Set the `enabled` attribute of the `multicast` element to `true`.
* Set `multicast-group`, `multicast-port`, `multicast-time-to-live`, etc. to your
multicast values.

The following is an example declarative configuration.

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <join>
            <multicast enabled="true">
                <multicast-group>224.2.2.3</multicast-group>
                <multicast-port>54327</multicast-port>
                <multicast-time-to-live>32</multicast-time-to-live>
                <multicast-timeout-seconds>2</multicast-timeout-seconds>
                <trusted-interfaces>
                    <interface>192.168.1.102</interface>
                </trusted-interfaces>
            </multicast>
        </join>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    join:
      multicast:
        enabled: true
        multicast-group: 224.2.2.3
        multicast-port: 54327
        multicast-time-to-live: 32
        multicast-timeout-seconds: 2
        trusted-interfaces:
          - 192.168.1.102
----

Pay attention to the `multicast-timeout-seconds` element. `multicast-timeout-seconds`
specifies the time in seconds that a member should wait for a valid multicast
response from another member running in the network before declaring itself the
leader member (the first member joined to the cluster) and creating its own cluster.
This only applies to the startup of members where no leader has been assigned yet. If
you specify a high value to `multicast-timeout-seconds`, such as 60 seconds, it means
that until a leader is selected, each member waits 60 seconds before moving on. Be careful
when providing a high value. Also, be careful not to set the value too low, or the members
might give up too early and create their own cluster.

NOTE: Multicast auto-discovery is not supported for Hazelcast native clients yet.
However, we offer Multicast Discovery Plugin for this purpose. See the
<<discovering-native-clients, Discovering Native Clients section>>.

[[discovering-native-clients]]
=== Discovering Native Clients

Hazelcast members and native Java clients can find each other with multicast
discovery plugin. This plugin is implemented using <<discovery-spi, Hazelcast Discovery SPI>>.
You should configure the plugin both at Hazelcast members and Java clients in order to
use multicast discovery.

To configure your cluster to have the multicast discovery plugin, follow
these steps:

* Set the `enabled` attribute of the `hazelcast.discovery.enabled`
property to `true`.
* Add multicast discovery strategy configuration to your XML file,
i.e., `<discovery-strategies>` element.

The following is an example declarative configuration.

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <properties>
        <property name="hazelcast.discovery.enabled">true</property>
    </properties>
    <network>
        <join>
            <discovery-strategies>
                <discovery-strategy class="com.hazelcast.spi.discovery.multicast.MulticastDiscoveryStrategy" enabled="true">
                    <properties>
                        <property name="group">224.2.2.3</property>
                        <property name="port">54327</property>
                    </properties>
                </discovery-strategy>
            </discovery-strategies>
        </join>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  properties:
    hazelcast.discovery.enabled: true
  network:
    join:
      discovery-strategies:
        discovery-strategy:
          enabled: true
          class: com.hazelcast.spi.discovery.multicast.MulticastDiscoveryStrategy
          properties:
            group: 224.2.2.3
            port: 54327
----

The following are the multicast discovery plugin configuration
properties with their descriptions:

* `group`: String value that is used to set the multicast group,
so that you can isolate your clusters.
* `port`: Integer value that is used to set the multicast port.


[[creating-cluster]]
=== Creating Clusters

You can create clusters using the `cluster-name` configuration
element.

You can separate and group your clusters in a simple way by specifying cluster names.
Example groupings can be by *development*, *production*, *test*, *app*, etc.
The following is an example declarative configuration.

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    <cluster-name>production</cluster-name>
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  cluster-name: production
----


You can also define the cluster configuration programmatically.
A JVM can host multiple Hazelcast instances. Each Hazelcast instance can only
participate in one group. Each Hazelcast instance only joins to its own group
and does not interact with other groups. The following code example creates
three separate Hazelcast instances--`h1` belongs to the `production` cluster,
while `h2` and `h3` belong to the `development` cluster.

[source,java]
----
include::{javasource}/GroupingClusters.java[tag=groupingclusters]
----

[[member-user-code-deployment]]
=== Deploying User Code on the Member

Hazelcast can dynamically load your custom classes or domain classes from other
members. A <<enabling-lite-members, lite member>> can be designated as a _class
repository_, but any member can _provide_ classes to other members. For this
purpose Hazelcast offers a distributed dynamic class loader.

The following is a brief working mechanism of the User Code Deployment feature:

. A new dynamic class loader is created to handle each operation.
. It first checks locally available classes, i.e. the member's classpath. If
the class is found, it is used.
. Then it checks the _cache_ of classes loaded from remote members or clients
(if caching is enabled on your local member, see the
<<configuring-user-code-deployment>> section). If your class is found there, it
is used.
. Finally, the dynamic class loader checks configured remote members, one by
one. If some member returns the class, it will be used. It can also put this
class into the local class cache as mentioned in the previous step.
. If the class is not found, `ClassNotFoundException` is thrown.
. The dynamic class loader is released after the operation is handled. A next
operation will load the class from the cache or re-fetch it.

NOTE: Using the user code deployment feature is a fit for your functional objects
like `Runnable`, `Callable` and `EntryProcessor`.
For the domain objects, we recommend you to use the
<<accessing-domain-objects-without-domain-classes, generic object interface>> (`GenericRecord`).

[[configuring-user-code-deployment]]
==== Configuring User Code Deployment

User Code Deployment feature is not enabled by default. You can control local
caching of the classes loaded from other members, control classes to be
provided to other members and create blacklists and whitelists of classes and
packages.

Following are example configuration snippets:

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <user-code-deployment enabled="true">
        <class-cache-mode>ETERNAL</class-cache-mode>
        <provider-mode>LOCAL_AND_CACHED_CLASSES</provider-mode>
        <blacklist-prefixes>com.foo,com.bar</blacklist-prefixes>
        <whitelist-prefixes>com.bar.MyClass</whitelist-prefixes>
        <provider-filter>HAS_ATTRIBUTE:lite</provider-filter>
    </user-code-deployment>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  user-code-deployment:
    enabled: true
    class-cache-mode: ETERNAL
    provider-mode: LOCAL_AND_CACHED_CLASSES
    blacklist-prefixes: com.foo,com.bar
    whitelist-prefixes: com.bar.MyClass
    provider-filter: HAS_ATTRIBUTE:lite
----

**Programmatic Configuration:**

[source,java]
----
include::{javasource}/MemberUCD.java[tag=ucd]
----

User Code Deployment on the member has the following configuration:

* `enabled`: Specifies whether dynamic class loading is enabled or not. Its
default value is "false" and it's a mandatory attribute. If feature is
disabled, the member will never load classes from other members or clients.
* `<class-cache-mode>`: Controls the local caching behavior for the classes
loaded from remote members (classes loaded from clients are always cached).
Available values are:
** `ETERNAL`: Cache the loaded classes locally. This is the default value and
suitable when you load long-living objects, such as domain objects stored in a map.
** `OFF`: Do not cache the loaded classes locally. It is suitable for loading
runnables, callables, entry processors, etc.
* `<provider-mode>`: Controls which classes are served to other cluster
members. Available values are:
** `LOCAL_AND_CACHED_CLASSES`: Serve classes loaded from both local classpath
and from other members. This is the default value.
** `LOCAL_CLASSES_ONLY`: Serve classes from the local classpath only. Classes
loaded from other members are used locally, but they are not served to other members.
** `OFF`: Never serve classes to other members.
* `<blacklist-prefixes>`: Comma separated class/package name prefixes that
the member will never attempt to load from other members and that the client
won't be allowed to upload. For example, if you set it to "com.foo", remote
loading of all classes from the "com.foo" package is prevented, including the
classes from all its sub-packages. If you set it to "com.foo.Class", then
"Class" and all classes starting with "Class" in the "com.foo" package are
blacklisted. There are built-in prefixes which are always blacklisted.
These are as follows:
** `javax.`
** `java.`
** `sun.`
** `com.hazelcast.`
* `<whitelist-prefixes>`: Comma separated name prefixes of classes/packages
only from which the classes are allowed to be loaded. It allows to quickly
configure remote loading only for classes from selected packages. It can be
used together with blacklisting. For example, you can whitelist the prefix
"com.foo" and blacklist the prefix "com.foo.secret". If the list is empty, all
classes are allowed.
* `<provider-filter>`: Filter to constrain members that can be used for a class
loading request when a class is not available locally. The value is in the
format "HAS_ATTRIBUTE:foo". When it is set to "HAS_ATTRIBUTE:foo", the class
loading request is only sent to the members which have "foo" as a
<<defining-member-attributes, member attribute>>. Setting this to null allows
loading of classes from all members. See an example in the next section.

[[example-for-filtering-members]]
==== Example for Filtering of Members

As described above, the configuration element `provider-filter` is used to
limit members that can be used to load classes. The attribute required in the
`provider-filter` must be set as a member attribute on the members from which
the classes are to be loaded. See the following examples provided as
programmatic configurations.

The example configuration below allows the Hazelcast member to load classes
only from members with the `class-provider` attribute set. It prevents from
asking any other member to provide a locally unavailable class:

[source,java]
----
include::{javasource}/MemberUCD.java[tag=hasAttributeConfig]
----

The example configuration below sets the attribute `class-provider` for a
member. Therefore the above member will be able to load classes from this
member:

[source,java]
----
include::{javasource}/MemberUCD.java[tag=memberAttributeConfig]
----

[[client-user-code-deployment]]
=== Deploying User Code from Clients

You can also deploy your code from the client side for the following
situations:

. You have objects that run on the cluster via the clients such as
`Runnable`, `Callable` and `EntryProcessor`.
. You have new user domain objects which need to be deployed into the cluster.

When this feature is enabled on the client, the client will deploy the classes
to the members when connecting. This way, when a client adds a new class, the
members do not require a restart to include it in their classpath.

You can also use the client permission policy to specify which clients
are permitted to use User Code Deployment. See the <<permissions, Permissions section>>.

NOTE:

[[configuring-client-user-code-deployment]]
==== Configuring Client User Code Deployment

Client User Code Deployment feature is not enabled by default. You can
configure this feature declaratively or programmatically.

NOTE: Using the user code deployment feature is a fit for your functional objects
like `Runnable`, `Callable` and `EntryProcessor`.
For the domain objects, we recommend you to use the
<<accessing-domain-objects-without-domain-classes, generic object interface>> (`GenericRecord`).

Following are example configuration snippets:

**Declarative Configuration:**

In your `hazelcast-client.xml/yaml`:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast-client>
    ...
    <user-code-deployment enabled="true">
        <jarPaths>
            <jarPath>/User/example/example.jar</jarPath>
            <jarPath>example.jar</jarPath> <!--from class path -->
            <jarPath>https://com.example.com/example.jar</jarPath>
            <jarPath>file://Users/example/example.jar</jarPath>
        </jarPaths>
        <classNames>
            <!-- for classes available in client's class path -->
            <className>example.ClassName</className>
            <className>example.ClassName2</className>
        </classNames>
    </user-code-deployment>
    ...
</hazelcast-client>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast-client:
  user-code-deployment
    enabled: true
    jarPaths:
      - /User/example/example.jar
      - example.jar
      - https://com.example.com/example.jar
      - file://Users/example/example.jar
    classNames:
      - example.ClassName
      - example.ClassName2
----


**Programmatic Configuration:**

[source,java]
----
include::{javasource}/ClientUCD.java[tag=clientucd]
----

[[client-user-code-deployment-note]]
===== Important to Know

The members have to be configured in a specific way for the feature to work
correctly:

* User Code Deployment must be enabled on the members. Otherwise, the classes
from the client will be ignored. Also blacklisted and non-whitelisted classes
will be ignored.
* All members must be providers, `provider-mode` must be set to
`LOCAL_AND_CACHED_CLASSES` on all members.
* No `provider-filter` must be configured.

The client uploads the classes only to one member. If the members don't load
classes from each other, other members won't see the class.

Here's a programmatic configuration of the members that will work with client
user code deployment:

[source,java]
----
include::{javasource}/ClientUCD.java[tag=configureMemberForClientUcd]
----

See the <<member-user-code-deployment, Member User Code Deployment section>>
for more information on enabling it on the member side and the configuration properties.

Classes deployed from clients are always cached on the members, no matter
whether `ETERNAL` or `OFF` is configured on the members.

===== Performance Considerations

The client always uploads all added classes and jars to one of the members,
whether it has them or not. So avoid adding large jar files for each connection
- if configured properly, the member will have the class the next time the
client connects.

===== Two Versions of a Class

If the client uploads a class and the member already has that class, an
exception is thrown if the byte code is different. If byte code is same, it is
ignored. Therefore classes uploaded from the client can't be updated with a new
version.

==== Adding User Library to CLASSPATH

When you want to use a Hazelcast feature in a non-Java client, you need to make
sure that the Hazelcast member recognizes it. For this, you can use the `/user-lib`
directory that comes with the Hazelcast package and deploy your own library to the member.
Let's say you use Hazelcast Node.js client and want to use an entry processor.
This processor should be `IdentifiedDataSerializable` or `Portable` in the Node.js client.
You need to implement the Java equivalents of the processor and its factory on the member side,
and put these compiled class or JAR files into the `/user-lib` directory. Then you can run
the `start.sh` script which adds them to the classpath.

The following is an example code which can be the Java equivalent of
entry processor in the Node.js client:

[source,java]
----
include::{javasource}/settingupclusters/IdentifiedEntryProcessor.java[tag=iep]
----

You can implement the above processor's factory as follows:

[source,java]
----
include::{javasource}/settingupclusters/IdentifiedFactory.java[tag=if]
----

And the following is the configuration for the above factory:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    <serialization>
        <data-serializable-factories>
            <data-serializable-factory factory-id="5">
                IdentifiedFactory
            </data-serializable-factory>
        </data-serializable-factories>
    </serialization>
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  serialization:
    data-serializable-factories:
      - factory-id: 5
        class-name: IdentifiedFactory
----

Then, you can start your Hazelcast member by using the start scripts
(`start.sh` or `start.bat`) in the `/bin` directory. The start scripts
automatically adds your class and JAR files to the classpath.

[[accessing-domain-objects-without-domain-classes]]
=== Accessing Domain Objects without Domain Classes - BETA

Hazelcast offers a generic object interface (`GenericRecord`) that is returned to the user
when the domain class is missing on the classpath.
For example, if `PortableFactory` is not given in the serialization configuration for a
portable object, the user domain class cannot be created, and Hazelcast returns `GenericRecord` instead.
In the previous Hazelcast IMDG releases, we were throwing `HazelcastSerializationException("Could not create Portable for class-id: " + classId)`
for the same situation.

`GenericRecord` is an immutable object. It allows you to read the field of objects via the related field names.
`GenericRecord` is applicable only to `Portable` objects.

You can use this feature when the cluster does not have the domain classes of the clients in a
client-server architecture. On remote calls like distributed executor service or entry processors,
you may need to access the domain object. In case the class of the domain object is not available on the cluster,
`GenericRecord` allows to access, read and write the objects
back without the class of the domain object on the classpath. Here is a read example with entry processor:

[source,java]
----
    map.executeOnKey(key, (EntryProcessor<Object, Object, Object>) entry -> {
             Object value = entry.getValue();
             GenericRecord genericRecord = (GenericRecord) value;

             int id = genericRecord.readInt("id");

             return null;
         });
----

An alternative approach introduced in the previous Hazelcast IMDG releases is the <<member-user-code-deployment, User Code Deployment>>
feature to deploy the classes from the client to the cluster.
However, it has a restriction: you can not upload
a new version of your class to the cluster if you use the portable versioning support.
Loading two different versions of the same class on the JVM is not a problem that we want to solve: using `GenericRecord`,
you can easily write different versions of your classes
from the clients and access them without using the User Code Deployment feature.

With the introduction of `GenericRecord`, User Code Deployment should be used only for functional objects like `Runnable`,
`Callable` and `EntryProcessor`.

You can also create a `GenericRecord` in portable format with `GenericRecord.Builder` as follows:

[source,java]
----
ClassDefinition classDefinition = new ClassDefinitionBuilder(PORTABLE_FACTORY_ID, EMPLOYEE_CLASS_ID)
                        .addUTFField("name").addIntField("id").build();

GenericRecord namedRecord = GenericRecord.Builder.portable(classDefinition)
                .writeUTF("name", "foo")
                .writeInt("id", 123).build();
----

Note that the class definitions are better to be created once and
used when creating different instances of the same type `GenericRecord`.

We have also added two convenience methods in `GenericRecord` for you to
avoid passing a class definition. For example, if you want to modify a value and
put it back using an entry processor, you don't need to create a class definition.
Instead you can create a builder from `GenericRecord` which carries the same class definition as follows:

[source,java]
----
map.executeOnKey("key", (EntryProcessor<Object, Object, Object>) entry -> {
            GenericRecord genericRecord = (GenericRecord) entry.getValue();
            GenericRecord modifiedGenericRecord = genericRecord.newBuilder()
                    .writeUTF("name","Kermit")
                    .writeLong("id", 4)
                    .writeInt("age",20)
                    .writeUTF("surname", "The Frog").build();
            entry.setValue(modifiedGenericRecord);
            return null;
        });
----

Another convenience method is `cloneWithBuilder`. This is useful if you want to update only
a couple of fields from the original `genericRecord`. In that case, the new builder carries
both `classDefinition` and values from the original
`genericRecord`. Here is the same example where we just update the age:

[source,java]
----
map.executeOnKey("key", (EntryProcessor<Object, Object, Object>) entry -> {
            GenericRecord genericRecord = (GenericRecord) entry.getValue();
            GenericRecord modifiedGenericRecord = genericRecord.cloneWithBuilder()
                    .writeInt("age",22).build();
            entry.setValue(modifiedGenericRecord);
            return null;
        });
----

Another use case of this feature is on the client side (could also be a member):
`GenericRecord` allows to read from/write to a cluster without having the related classes on the classpath.
A client could work with the cluster without introducing the `PortableFactory` at the start.
In this case, the client works with ``GenericRecord``s instead of domain classes.
An example code snippet on the client side with a map is shown below:

[source,java]
----
        GenericRecord record = (GenericRecord) map.get("key1");
        String name = record.readUTF("name");
        int id = record.readInt("id");

        GenericRecord newGenericRecord = genericRecord.cloneWithBuilder()
                .writeInt("age",22).build();

        map.put("key2", newGenericRecord);
----

[[partition-group-configuration]]
=== Partition Group Configuration

Hazelcast distributes key objects into partitions using the consistent
hashing algorithm. Multiple replicas are created for each partition and
those partition replicas are distributed among Hazelcast members. An entry
is stored in the members that own replicas of the partition to which the entry's
key is assigned. The total partition count is 271 by default; you can change it
with the configuration property `hazelcast.partition.count`. See the
<<system-properties, System Properties appendix>>.

Hazelcast member that owns the primary replica of a partition is called as
the partition owner. Other replicas are called backups. Based on the configuration,
a key object can be kept in multiple replicas of a partition. A member can hold at
most one replica of a partition (ownership or backup).

By default, Hazelcast distributes partition replicas randomly and equally among
the cluster members, assuming all members in the cluster are identical. But what
if some members share the same JVM or physical machine or chassis and you want
backups of these members to be assigned to members in another machine or chassis?
What if processing or memory capacities of some members are different and you
do not want an equal number of partitions to be assigned to all members?

To deal with such scenarios, you can group members in the same JVM (or physical machine)
or members located in the same chassis. Or you can group members to create identical
capacity. We call these groups **partition groups**. Partitions are assigned to those
partition groups instead of individual members. Backup replicas of a partition which is
owned by a partition group are located in other partition groups.

[[grouping-types]]
==== Grouping Types

When you enable partition grouping, Hazelcast presents the following choices
for you to configure partition groups.

===== HOST_AWARE

You can group members automatically using the IP addresses of members, so members
sharing the same network interface are grouped together. All members on the same
host (IP address or domain name) form a single partition group. This helps to avoid
data loss when a physical server crashes, because multiple replicas of the same
partition are not stored on the same host. But if there are multiple network
interfaces or domain names per physical machine, this assumption is invalid.

The following are declarative and programmatic configuration snippets that
show how to enable `HOST_AWARE` grouping:

```
<partition-group enabled="true" group-type="HOST_AWARE" />
```

[source,java]
----
Config config = ...;
PartitionGroupConfig partitionGroupConfig = config.getPartitionGroupConfig();
partitionGroupConfig.setEnabled( true )
    .setGroupType( MemberGroupType.HOST_AWARE );
----

===== CUSTOM

You can do custom grouping using Hazelcast's interface matching configuration.
This way, you can add different and multiple interfaces to a group. You can also
use wildcards in the interface addresses. For example, the users can create rack-aware
or data warehouse partition groups using custom partition grouping.

The following are declarative and programmatic configuration examples that show
how to enable and use `CUSTOM` grouping:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <partition-group enabled="true" group-type="CUSTOM">
        <member-group>
            <interface>10.10.0.*</interface>
            <interface>10.10.3.*</interface>
            <interface>10.10.5.*</interface>
        </member-group>
        <member-group>
            <interface>10.10.10.10-100</interface>
            <interface>10.10.1.*</interface>
            <interface>10.10.2.*</interface>
        </member-group>
    </partition-group>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  partition-group:
    enabled: true
    group-type: CUSTOM
    member-group:
      - - 10.10.0.*
        - 10.10.3.*
        - 10.10.5.*
      - - 10.10.10.10-100
        - 10.10.1.*
        - 10.10.2.*
----

[source,java]
----
include::{javasource}/PartitionGrouping.java[tag=partitiongrouping]
----

NOTE: While your cluster was forming, if you configured your members to
discover each other by their IP addresses, you should use the IP addresses
for the `<interface>` element. If your members discovered each other by their
host names, you should use host names.

===== PER_MEMBER

You can give every member its own group. Each member is a group of its own
and primary and backup partitions are distributed randomly (not on the same
physical member). This gives the least amount of protection and is the default
configuration for a Hazelcast cluster. This grouping type provides good redundancy
when Hazelcast members are on separate hosts. However, if multiple instances
run on the same host, this type is not a good option.

The following are declarative and programmatic configuration snippets that
show how to enable `PER_MEMBER` grouping:

```
<partition-group enabled="true" group-type="PER_MEMBER" />
```

[source,java]
----
Config config = ...;
PartitionGroupConfig partitionGroupConfig = config.getPartitionGroupConfig();
partitionGroupConfig.setEnabled( true )
    .setGroupType( MemberGroupType.PER_MEMBER );
----

===== ZONE_AWARE

You can use ZONE_AWARE configuration with link:https://github.com/hazelcast/hazelcast-kubernetes[Hazelcast Kubernetes^],
link:https://github.com/hazelcast/hazelcast-aws[Hazelcast AWS^],
link:https://github.com/hazelcast/hazelcast-gcp[Hazelcast GCP^],
link:https://github.com/hazelcast/hazelcast-jclouds[Hazelcast jclouds^] or
link:https://github.com/hazelcast/hazelcast-azure[Hazelcast Azure^] Discovery Service plugins.

As discovery services, these plugins put zone information to the Hazelcast
<<defining-member-attributes, member attributes>> map during the discovery process.
When ZONE_AWARE is configured as partition group type, Hazelcast creates the partition
groups with respect to member attributes map entries that include zone information.
That means backups are created in the other zones and each zone is accepted as one partition group.

NOTE: When using the ZONE_AWARE partition grouping, a Hazelcast cluster spanning
multiple AZs should have an equal number of members in each AZ. Otherwise,
it results in uneven partition distribution among the members.

The following is the list of supported attributes which is set by the
Discovery Service plugins during a Hazelcast member start-up:

* `hazelcast.partition.group.zone`: For the zones in the same area.
* `hazelcast.partition.group.rack`: For different racks in the same zone.
* `hazelcast.partition.group.host`: For a shared physical member if virtualization is used.

NOTE: Hazelcast jclouds plugin offers rack or host information in addition to
zone information based on the cloud provider. In such cases, Hazelcast looks for zone,
rack and host information in the given order and create partition groups with available information.

The following are declarative and programmatic configuration snippets
that show how to enable `ZONE_AWARE` grouping:

```
<partition-group enabled="true" group-type="ZONE_AWARE" />
```

[source,java]
----
Config config = ...;
PartitionGroupConfig partitionGroupConfig = config.getPartitionGroupConfig();
partitionGroupConfig.setEnabled( true )
    .setGroupType( MemberGroupType.ZONE_AWARE );
----

===== SPI

You can provide your own partition group implementation using the SPI configuration.
To create your partition group implementation, you need to first extend the
`DiscoveryStrategy` class of the discovery service plugin, override the method
`public PartitionGroupStrategy getPartitionGroupStrategy()` and return the `PartitionGroupStrategy`
configuration in that overridden method.

The following code covers the implementation steps mentioned in the above paragraph:

[source,java]
----
public class CustomDiscovery extends AbstractDiscoveryStrategy {

    public CustomDiscovery(ILogger logger, Map<String, Comparable> properties) {
        super(logger, properties);
    }

    @Override
    public Iterable<DiscoveryNode> discoverNodes() {
        Iterable<DiscoveryNode> iterable = //your implementation
        return iterable;
    }

    @Override
    public PartitionGroupStrategy getPartitionGroupStrategy() {
        return new CustomPartitionGroupStrategy();
    }

    private class CustomPartitionGroupStrategy implements PartitionGroupStrategy {
        @Override
        public Iterable<MemberGroup> getMemberGroups() {
            Iterable<MemberGroup> iterable = //your implementation
            return iterable;
        }
    }
}
----

[[logging-configuration]]
=== Logging Configuration

Hazelcast has a flexible logging configuration and does not depend on
any logging framework except JDK logging. It has built-in adapters
for a number of logging frameworks and it also supports custom loggers
by providing logging interfaces.

To use the built-in adapters, set the `hazelcast.logging.type` property
to one of the predefined types below:

* **jdk**: JDK logging (default)
* **log4j**: Log4j
* **log4j2**: Log4j2
* **slf4j**: Slf4j
* **none**: disable logging

You can set `hazelcast.logging.type` through declarative configuration,
programmatic configuration or JVM system property.

NOTE: If you choose to use `log4j`, `log4j2`, or `slf4j`, you should include
the proper dependencies in the classpath.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <properties>
        <property name="hazelcast.logging.type">log4j</property>
    </properties>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  properties:
    hazelcast.logging.type: log4j
----

**Programmatic Configuration**

[source,java]
----
Config config = new Config() ;
config.setProperty( "hazelcast.logging.type", "log4j" );
----

**System Property**

* using the `java -Dhazelcast.logging.type=slf4j` JVM parameter
* using `System.setProperty( "hazelcast.logging.type", "none" );` System class


If the provided logging mechanisms are not satisfactory, you can implement
your own using the custom logging feature. To use it, implement the
`com.hazelcast.logging.LoggerFactory` and `com.hazelcast.logging.ILogger`
interfaces and set the system property `hazelcast.logging.class` as your
custom `LoggerFactory` class name.

```
-Dhazelcast.logging.class=foo.bar.MyLoggingFactory
```

You can also listen to logging events generated by Hazelcast runtime
by registering ``LogListener``s to `LoggingService`.

[source,java]
----
LogListener listener = new LogListener() {
  public void log( LogEvent logEvent ) {
    // do something
  }
};
HazelcastInstance instance = Hazelcast.newHazelcastInstance();
LoggingService loggingService = instance.getLoggingService();
loggingService.addLogListener( Level.INFO, listener );
----

Through the `LoggingService`, you can get the currently used
ILogger implementation and log your own messages too.

NOTE: If you are not using command line for configuring logging, you should be careful
about Hazelcast classes. They may be defaulted to `jdk` logging before newly configured
logging is read. When logging mechanism is selected, it will not change.

Below are example configurations for Log4j2 and Log4j. Note that Hazelcast does not
recommend any specific logging library, these examples are provided only to demonstrate
how to configure the logging. You can use your custom logging as explained above.

==== Example Log4j2 Configuration

Specify the logging type as Log4j2 and a separate logging configuration file as shown below.

Using JVM arguments:

```
-Dhazelcast.logging.type=log4j2
-Dlog4j.configurationFile=/path/to/properties/log4j2.properties
```

Using declarative configuration (`hazelcast.xml/yaml`):

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <properties>
        <property name="hazelcast.logging.type">log4j2</property>
        <property name="log4j2.configuration">/path/to/properties/log4j2.properties</property>
    </properties>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  properties:
    hazelcast.logging.type: log4j2
    log4j2.configuration: /path/to/properties/log4j2.properties
----

Following is an example `log4j2.properties` file:

[source,plain]
----
rootLogger=file
rootLogger.level=info
property.filepath=/path/to/log/files
property.filename=hazelcast

appender.file.type=RollingFile
appender.file.name=RollingFile
appender.file.fileName=${filepath}/${filename}.log
appender.file.filePattern=${filepath}/${filename}-%d{yyyy-MM-dd}-%i.log.gz
appender.file.layout.type=PatternLayout
appender.file.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
appender.file.policies.type=Policies
appender.file.policies.time.type=TimeBasedTriggeringPolicy
appender.file.policies.time.interval=1
appender.file.policies.time.modulate=true
appender.file.policies.size.type=SizeBasedTriggeringPolicy
appender.file.policies.size.size=50MB
appender.file.strategy.type=DefaultRolloverStrategy
appender.file.strategy.max=100

rootLogger.appenderRefs=file
rootLogger.appenderRef.file.ref=RollingFile

#Hazelcast specific logs.

#log4j.logger.com.hazelcast=debug

#log4j.logger.com.hazelcast.cluster=debug
#log4j.logger.com.hazelcast.partition=debug
#log4j.logger.com.hazelcast.partition.InternalPartitionService=debug
#log4j.logger.com.hazelcast.nio=debug
#log4j.logger.com.hazelcast.hibernate=debug
----

To enable the debug logs for all Hazelcast operations uncomment the below line
in the above configuration file:

```
log4j.logger.com.hazelcast=debug
```


If you do not need detailed logs, the default settings are enough.
Using the Hazelcast specific lines in the above configuration file,
you can select to see specific logs (cluster, partition, hibernate, etc.) in desired levels.

You can also use the `hazelcast.logging.details.enabled` property to
specify whether the name, IP address and version of the cluster are included
in the logs. When there are lots of log lines, it may be hard to follow.
When set to `false`, those information will not appear.

==== Example Log4j Configuration

Its configuration is similar to that of Log4j2. Below is the JVM argument way of
specifying the logging type and configuration file:

```
-Dhazelcast.logging.type=log4j
-Dlog4j.configuration=file:/path/to/properties/log4j.properties
```


Following is an example `log4j.properties` file:

[source,plain]
----
log4j.rootLogger=INFO,file

log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=/path/to/log/files/hazelcast.log
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %p [%c{1}] - %m%n
log4j.appender.file.maxFileSize=50MB
log4j.appender.file.maxBackupIndex=100
log4j.appender.file.threshold=DEBUG

#log4j.logger.com.hazelcast=debug

#log4j.logger.com.hazelcast.cluster=debug
#log4j.logger.com.hazelcast.partition=debug
#log4j.logger.com.hazelcast.partition.InternalPartitionService=debug
#log4j.logger.com.hazelcast.nio=debug
#log4j.logger.com.hazelcast.hibernate=debug
----


[[other-network-configurations]]
=== Other Network Configurations

All network related configurations are performed via the `network` element
in the Hazelcast XML configuration file or the class `NetworkConfig`
when using programmatic configuration. Following subsections describe the
available configurations that you can perform under the `network` element.

[[public-address]]
==== Public Address

`public-address` overrides the public address of a member. By default, a member
selects its socket address as its public address. But behind a network address translation (NAT),
two endpoints (members) may not be able to see/access each other.
If both members set their public addresses to their defined addresses on NAT,
then that way they can communicate with each other. In this case, their public addresses
are not an address of a local network interface but a virtual address defined by NAT.
It is optional to set and useful when you have a private cloud.
Note that, the value for this element should be given in the format *`host IP address:port number`*.
See the following examples.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <public-address>11.22.33.44:5555</public-address>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    public-address: 11.22.33.44:5555
----

**Programmatic Configuration:**

[source,java]
----
Config config = new Config();
config.getNetworkConfig()
    .setPublicAddress( "11.22.33.44:5555" );
----

[[port]]
==== Port

You can specify the ports that Hazelcast uses to communicate between cluster members.
Its default value is `5701`. The following are example configurations.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <port port-count="20" auto-increment="true">5701</port>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    port:
      auto-increment: true
      port-count: 20
      port: 5701
----


**Programmatic Configuration:**

[source,java]
----
Config config = new Config();
config.getNetworkConfig().setPort( 5701 )
    .setPortAutoIncrement( true ).setPortCount( 20 );
----

According to the above example, Hazelcast tries to find free ports between 5701 and 5720.

`port` has the following attributes.

* `port-count`: By default, Hazelcast tries 100 ports to bind. Meaning that,
if you set the value of port as 5701, as members are joining to the cluster,
Hazelcast tries to find ports between 5701 and 5801. You can choose to change the
port count in the cases like having large instances on a single machine or
willing to have only a few ports to be assigned. The parameter `port-count`
is used for this purpose, whose default value is 100.
* `auto-increment`:  In some cases you may want to choose to use only one port.
In that case, you can disable the auto-increment feature of `port` by setting
`auto-increment` to `false`. The `port-count` attribute is not used when
auto-increment feature is disabled.

[[outbound-ports]]
==== Outbound Ports

By default, Hazelcast lets the system pick up an ephemeral port during socket bind operation.
But security policies/firewalls may require you to restrict outbound ports to be
used by Hazelcast-enabled applications. To fulfill this requirement, you can configure
Hazelcast to use only defined outbound ports. The following are example configurations.


**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <outbound-ports>
            <!-- ports between 33000 and 35000 -->
            <ports>33000-35000</ports>
            <!-- comma separated ports -->
            <ports>37000,37001,37002,37003</ports>
            <ports>38000,38500-38600</ports>
        </outbound-ports>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    outbound-ports:
      - 33000-35000
      - 37000,37001,37002,37003
      - 38000,38500-38600
----

**Programmatic Configuration:**

[source,java]
----
...
NetworkConfig networkConfig = config.getNetworkConfig();
// ports between 35000 and 35100
networkConfig.addOutboundPortDefinition("35000-35100");
// comma separated ports
networkConfig.addOutboundPortDefinition("36001, 36002, 36003");
networkConfig.addOutboundPort(37000);
networkConfig.addOutboundPort(37001);
...
----

NOTE: You can use port ranges and/or comma separated ports.

As shown in the programmatic configuration, you use the method `addOutboundPort`
to add only one port. If you need to add a group of ports, then use the method `addOutboundPortDefinition`.

In the declarative configuration, the element `ports` can be used for both single and
multiple port definitions. When you set this element to  `0` or  `*`,
your operating system (not Hazelcast) selects a free port from the ephemeral range.

[[reuse-address]]
==== Reuse Address

When you shutdown a cluster member, the server socket port goes into the
`TIME_WAIT` state for the next couple of minutes. If you start the member right after
shutting it down, you may not be able to bind it to the same port because it is in the
`TIME_WAIT` state. If you set the `reuse-address` element to `true`, the `TIME_WAIT` state
is ignored and you can bind the member to the same port again.

The following are example configurations.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <reuse-address>true</reuse-address>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    reuse-address: true
----

**Programmatic Configuration:**

[source,java]
----
...
NetworkConfig networkConfig = config.getNetworkConfig();

networkConfig.setReuseAddress( true );
...
----

[[join]]
==== Join

The `join` configuration element is used to discover Hazelcast members and enable them
to form a cluster. Hazelcast provides Auto Detection, Multicast, TCP/IP, AWS, Kubernetes, Azure, GCP, Eureka, and more.
These mechanisms are explained the <<discovery-mechanisms, Discovery Mechanisms section>>.
This section describes all the sub-elements and attributes of `join` element.
The following are example configurations.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <join>
            <auto-detection enabled="true" />
            <multicast enabled="false">
                <multicast-group>224.2.2.3</multicast-group>
                <multicast-port>54327</multicast-port>
                <multicast-time-to-live>32</multicast-time-to-live>
                <multicast-timeout-seconds>2</multicast-timeout-seconds>
                <trusted-interfaces>
                    <interface>192.168.1.102</interface>
                </trusted-interfaces>
            </multicast>
            <tcp-ip enabled="false">
                <required-member>192.168.1.104</required-member>
                <member>192.168.1.104</member>
                <members>192.168.1.105,192.168.1.106</members>
            </tcp-ip>
            <aws enabled="false">
                <access-key>my-access-key</access-key>
                <secret-key>my-secret-key</secret-key>
                <region>us-west-1</region>
                <host-header>ec2.amazonaws.com</host-header>
                <security-group-name>hazelcast-sg</security-group-name>
                <tag-key>type</tag-key>
                <tag-value>hz-members</tag-value>
            </aws>
            <discovery-strategies>
                <discovery-strategy ... />
            </discovery-strategies>
        </join>
    </network>
    ...
</hazelcast>

----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    join:
      auto-detection:
        enabled: true
      multicast:
        enabled: false
        multicast-group: 224.2.2.3
        multicast-port: 54327
        multicast-time-to-live: 32
        multicast-timeout-seconds: 2
        trusted-interfaces:
          - 192.168.1.102
      tcp-ip:
        enabled: false
        required-member: 192.168.1.104
        member-list:
          - 192.168.1.104
          - 192.168.1.105,192.168.1.106
      aws:
        enabled: false
        access-key: my-access-key
        secret-key: my-secret-key
        region: us-west-1
        host-header: ec2.amazonaws.com
        security-group-name: hazelcast-sg
        tag-key: type
        tag-value: hz-nodes
      discovery-strategies:
        discovery-strategy:
          ...
----

**Programmatic Configuration:**

[source,java]
----
Config config = new Config();
NetworkConfig network = config.getNetworkConfig();
JoinConfig join = network.getJoin();
join.getTcpIpConfig().addMember( "10.45.67.32" ).addMember( "10.45.67.100" )
            .setRequiredMember( "192.168.10.100" ).setEnabled( true );
----

The `join` element has the following sub-elements and attributes.

[[auto-detection-element]]
===== auto-detection element

The `auto-detection` element includes the following parameters:

* `enabled`: Enables <<discovering-members-auto-detection, Hazelcast Auto Detection>>; `true` by default.

[[multicast-element]]
===== multicast element

The `multicast` element includes parameters to fine tune the multicast join mechanism.

* `enabled`: Specifies whether the multicast discovery is enabled or not, `true` or `false`.
* `multicast-group`: The multicast group IP address. Specify it when you want to create
clusters within the same network. Values can be between 224.0.0.0 and 239.255.255.255.
Its default value is 224.2.2.3.
* `multicast-port`: The multicast socket port that the Hazelcast member listens to and
sends discovery messages through. Its default value is 54327.
* `multicast-time-to-live`: Time-to-live value for multicast packets sent out to control
the scope of multicasts. See more information http://www.tldp.org/HOWTO/Multicast-HOWTO-2.html[here].
* `multicast-timeout-seconds`: Only when the members are starting up, this timeout (in seconds)
specifies the period during which a member waits for a multicast response from another member.
For example, if you set it as 60 seconds, each member waits for 60 seconds until a leader
member is selected. Its default value is 2 seconds.
* `trusted-interfaces`: Includes IP addresses of trusted members. When a member wants to
join to the cluster, its join request is rejected if it is not a trusted member. You can
give an IP addresses range using the wildcard (\*) on the last digit of IP address,
e.g., 192.168.1.* or 192.168.1.100-110.

NOTE: If you prefer to use the multicast mechanism, make sure that your network is enclosed and secure.
See the <<multicast, Multicast section>>.

[[tcp-ip-element]]
===== tcp-ip element

The `tcp-ip` element includes parameters to fine tune the TCP/IP join mechanism.

* `enabled`: Specifies whether the TCP/IP discovery is enabled or not.
Values can be `true` or `false`.
* `required-member`: IP address of the required member. Cluster is only
formed if the member with this IP address is found.
* `member`: IP address(es) of one or more well known members. Once members
are connected to these well known ones, all member addresses are communicated
with each other. You can also give comma separated IP addresses using the `members` element.
+
NOTE: `tcp-ip` element also accepts the `interface` parameter. See the
<<interfaces, Interfaces element description>>.
+
* `connection-timeout-seconds`: Defines the connection timeout in seconds.
This is the maximum amount of time Hazelcast is going to try to connect to a well
known member before giving up. Setting it to a too low value could mean that a
member is not able to connect to a cluster. Setting it to a too high value means
that member startup could slow down because of longer timeouts, for example when
a well known member is not up. Increasing this value is recommended if you have many
IPs listed and the members cannot properly build up the cluster. Its default value is 5 seconds.

[[aws-element]]
===== aws element

The `aws` element includes parameters to allow the members to form a cluster
on the Amazon EC2 and ECS environments.

For details, please check the
link:https://github.com/hazelcast/hazelcast-aws[Hazelcast AWS Discovery plugin documentation].

[[azure-element]]
===== azure element

The `azure` element includes parameters to allow the members to form a cluster on the Azure VM machines.

For details, please check the
link:https://github.com/hazelcast/hazelcast-azure[Hazelcast Azure Discovery plugin documentation].

[[gcp-element]]
===== gcp element

The `gcp` element includes parameters to allow the members to form a cluster on the GCP Compute VM instances.

For details, please check the
link:https://github.com/hazelcast/hazelcast-gcp[Hazelcast GCP Discovery plugin documentation].

[[kubernetes-element]]
===== kubernetes element

The `kubernetes` element includes parameters to allow the members to form a cluster on the Kubernetes environment.

For details, please check the
link:https://github.com/hazelcast/hazelcast-kubernetes[Hazelcast Kubernetes Discovery plugin documentation].

[[discovery-strategies-element]]
===== discovery-strategies element

The `discovery-strategies` element configures internal or external discovery
strategies based on the Hazelcast Discovery SPI. For further information, see
the <<discovery-spi, Discovery SPI section>> and the vendor documentation of
the used discovery strategy.

[[interfaces]]
==== Interfaces

You can specify which network interfaces that Hazelcast should use.
Servers mostly have more than one network interface, so you may want to list
the valid IPs. **Range characters `"\*"` and `"-"`** can be used for simplicity.
For instance, 10.3.10.* refers to IPs between 10.3.10.0 and 10.3.10.255.
Interface 10.3.10.4-18 refers to IPs between 10.3.10.4 and 10.3.10.18
(4 and 18 included). If network interface configuration is enabled
(it is disabled by default) and if Hazelcast cannot find a matching interface,
then it prints a message on the console and does not start on that member.

The following are example configurations.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <interfaces enabled="true">
            <interface>10.3.16.*</interface>
            <interface>10.3.10.4-18</interface>
            <interface>192.168.1.3</interface>
        </interfaces>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    interfaces:
      enabled: true
      interfaces:
        - 10.3.16.*
        - 10.3.10.4-18
        - 192.168.1.3
----

**Programmatic Configuration:**

[source,java]
----
Config config = new Config();
NetworkConfig network = config.getNetworkConfig();
InterfacesConfig interfaceConfig = network.getInterfaces();
interfaceConfig.setEnabled( true )
            .addInterface( "192.168.1.3" );
----

[[ipv6-support]]
==== IPv6 Support

Hazelcast supports IPv6 addresses seamlessly (This support is switched
off by default, see the note at the end of this section).

All you need is to define IPv6 addresses or interfaces in the network
configuration. The only current limitation is that you cannot define
wildcard IPv6 addresses in the TCP/IP join configuration (`tcp-ip` element).
<<interfaces, Interfaces>> configuration does not have this limitation,
you can configure wildcard IPv6 interfaces in the same way as IPv4 interfaces.

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <port auto-increment="true">5701</port>
        <join>
            <multicast enabled="false">
                <multicast-group>FF02:0:0:0:0:0:0:1</multicast-group>
                <multicast-port>54327</multicast-port>
            </multicast>
            <tcp-ip enabled="true">
                <member>[fe80::223:6cff:fe93:7c7e]:5701</member>
                <interface>192.168.1.0-7</interface>
                <interface>192.168.1.*</interface>
                <interface>fe80:0:0:0:45c5:47ee:fe15:493a</interface>
            </tcp-ip>
        </join>
        <interfaces enabled="true">
            <interface>10.3.16.*</interface>
            <interface>10.3.10.4-18</interface>
            <interface>fe80:0:0:0:45c5:47ee:fe15:*</interface>
            <interface>fe80::223:6cff:fe93:0-5555</interface>
        </interfaces>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    port:
      auto-increment: true
      port: 5701
    join:
      multicast:
        enabled: false
        multicast-group: FF02:0:0:0:0:0:0:1
        multicast-port: 54327
      tcp-ip:
        enabled: true
        member: [fe80::223:6cff:fe93:7c7e]:5701
        interface: 192.168.1.0-7
        interface: 192.168.1.*
        interface: fe80:0:0:0:45c5:47ee:fe15:493a
    interfaces:
      enabled: true
      interfaces:
        - 10.3.16.*
        - 10.3.10.4-18
        - fe80:0:0:0:45c5:47ee:fe15:*
        - fe80::223:6cff:fe93:0-5555
----

JVM has two system properties for setting the preferred protocol stack
(IPv4 or IPv6) as well as the preferred address family types (inet4 or inet6).
On a dual stack machine, IPv6 stack is preferred by default, you can change this
through the `java.net.preferIPv4Stack=<true|false>` system property. When querying
name services, JVM prefers IPv4 addresses over IPv6 addresses and returns an IPv4
address if possible. You can change this through `java.net.preferIPv6Addresses=<true|false>`
system property.

See also additional link:http://docs.oracle.com/javase/1.5.0/docs/guide/net/ipv6_guide/[details on IPv6 support in Java^].

NOTE: IPv6 support has been switched off by default, since some platforms have issues
using the IPv6 stack. Some other platforms such as Amazon AWS have no support at all.
To enable IPv6 support, just set configuration property `hazelcast.prefer.ipv4.stack`
to *false*. See the <<system-properties, System Properties appendix>> for details.

[[member-address-provides-spi]]
==== Member Address Provider SPI

NOTE: This SPI is not intended to provide addresses of other cluster members with
which the Hazelcast instance forms a cluster. To do that, see the
<<other-network-configurations, previous sections>> above.

By default, Hazelcast chooses the public and bind address. You can influence on the
choice by defining a `public-address` in the configuration or by using other
properties mentioned above. In some cases, though, these properties are not
enough and the default address picking strategy chooses wrong addresses.
This may be the case when deploying Hazelcast in some cloud environments,
such as AWS, when using Docker or when the instance is deployed behind a NAT
and the `public-address` property is not enough (see the <<public-address, Public Address section>>).

In these cases, it is possible to configure the bind and public address
in a more advanced way. You can provide an implementation of the
`com.hazelcast.spi.MemberAddressProvider` interface which provides
the bind and public address. The implementation may then choose these
addresses in any way - it may read from a system property or file or
even invoke a web service to retrieve the public and private address.

The details of the implementation depend heavily on the environment in which
Hazelcast is deployed. As such, we now demonstrate how to configure Hazelcast
to use a simplified custom member address provider SPI implementation.
An example implementation is shown below:

[source,java]
----
public static final class SimpleMemberAddressProvider implements MemberAddressProvider {
    @Override
    public InetSocketAddress getBindAddress() {
        // determine the address using some configuration, calling an API, ...
        return new InetSocketAddress(hostname, port);
    }

    @Override
    public InetSocketAddress getPublicAddress() {
        // determine the address using some configuration, calling an API, ...
        return new InetSocketAddress(hostname, port);
    }
}
----

Note that if the bind address port is `0` then it uses a port as configured
in the Hazelcast network configuration (see the <<port, Port section>>).
If the public address port is set to `0` then it broadcasts the same port that
it is bound to. If you wish to bind to any local interface, you may return
`new InetSocketAddress((InetAddress) null, port)` from the `getBindAddress()` address.

The following configuration examples contain properties that are provided to the
constructor of the provider class. If you do not provide any properties, the class
may have either a no-arg constructor or a constructor accepting a single
`java.util.Properties` instance. On the other hand, if you do provide properties
in the configuration, the class must have a constructor accepting a single
`java.util.Properties` instance.


**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <network>
        <member-address-provider enabled="true">
            <class-name>SimpleMemberAddressProvider</class-name>
            <properties>
                <property name="prop1">prop1-value</property>
                <property name="prop2">prop2-value</property>
            </properties>
        </member-address-provider>
        <!-- other network configurations -->
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    member-address-provider:
      enabled: true
      class-name: SimpleMemberAddressProvider
      properties:
        prop1: prop1-value
        prop2: prop2-value
    ...
----

**Programmatic Configuration:**

[source,java]
----
Config config = new Config();
MemberAddressProviderConfig memberAddressProviderConfig = config.getNetworkConfig().getMemberAddressProviderConfig();
memberAddressProviderConfig
      .setEnabled(true)
      .setClassName(MemberAddressProviderWithStaticProperties.class.getName());
Properties properties = memberAddressProviderConfig.getProperties();
properties.setProperty("prop1", "prop1-value");
properties.setProperty("prop2", "prop2-value");

config.getNetworkConfig().getJoin().getAutoDetectionConfig().setEnabled(false);

// perform other configuration

Hazelcast.newHazelcastInstance(config);
----

[[failure-detector-configuration]]
=== Failure Detector Configuration

A failure detector is responsible to determine if a member in the cluster is
unreachable or crashed. The most important problem in failure detection is to
distinguish whether a member is still alive but slow or has crashed. But according
to the famous link:http://dl.acm.org/citation.cfm?doid=3149.214121[FLP result^],
it is impossible to distinguish a crashed member from a slow one in an asynchronous
system. A workaround to this limitation is to use unreliable failure detectors.
An unreliable failure detector allows a member to suspect that others have failed,
usually based on liveness criteria but it can make mistakes to a certain degree.

Hazelcast has the following built-in failure detectors: Deadline Failure Detector
and Phi Accrual Failure Detector.

There is also a Ping Failure Detector, that, if enabled, works in parallel with
the above ones, but identifies
the failures on OSI Layer 3 (Network Layer). This detector is by default disabled.

Note that, Hazelcast also offers failure detectors for its Java client.
See the <<java-client-failure-detectors, Client Failure Detectors section>> for more information.

==== Deadline Failure Detector

_Deadline Failure Detector_ uses an absolute timeout for missing/lost
heartbeats. After timeout, a member is considered as crashed/unavailable
and marked as suspected.

_Deadline Failure Detector_ has the following configuration properties:

* `hazelcast.heartbeat.interval.seconds`: This is the interval at which
member heartbeat messages are sent to each other.
* `hazelcast.max.no.heartbeat.seconds`: This is the timeout which defines
when a cluster member is suspected because it has not sent any heartbeats.

To use _Deadline Failure Detector_, the configuration property
`hazelcast.heartbeat.failuredetector.type` should be set to `"deadline"`.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <properties>
        <property name="hazelcast.heartbeat.failuredetector.type">deadline</property>
        <property name="hazelcast.heartbeat.interval.seconds">5</property>
        <property name="hazelcast.max.no.heartbeat.seconds">120</property>
    </properties>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  properties:
    hazelcast.heartbeat.failuredetector.type: deadline
    hazelcast.heartbeat.interval.seconds: 5
    hazelcast.max.no.heartbeat.seconds: 120
----

**Programmatic Configuration:**

[source,java]
----
Config config = ...;
config.setProperty("hazelcast.heartbeat.failuredetector.type", "deadline");
config.setProperty("hazelcast.heartbeat.interval.seconds", "5");
config.setProperty("hazelcast.max.no.heartbeat.seconds", "120");
[...]
----

NOTE: _Deadline Failure Detector_ is the default failure detector in Hazelcast.

[[phi-accrual-failure-detector]]
==== Phi Accrual Failure Detector

This is the failure detector based on
link:https://www.computer.org/csdl/proceedings/srds/2004/2239/00/22390066-abs.html[The Phi Accrual Failure Detector' by Hayashibara et al.^]

Phi Accrual Failure Detector keeps track of the intervals between heartbeats
in a sliding window of time and measures the mean and variance of these
samples and calculates a value of suspicion level (Phi). The value of phi
increases when the period since the last heartbeat gets longer. If the network
becomes slow or unreliable, the resulting mean and variance increase, there needs
to be a longer period for which no heartbeat is received before the member is suspected. 

The `hazelcast.heartbeat.interval.seconds` and `hazelcast.max.no.heartbeat.seconds`
properties still can be used as period of heartbeat messages and deadline of
heartbeat messages. Since _Phi Accrual Failure Detector_ is adaptive to network
conditions, a much lower `hazelcast.max.no.heartbeat.seconds` can be defined than
_Deadline Failure Detector_'s timeout.

In addition to the above two properties, _Phi Accrual Failure Detector_ has the
following configuration properties:

* `hazelcast.heartbeat.phiaccrual.failuredetector.threshold`: This is the phi
threshold for suspicion. After calculated phi exceeds this threshold, a member
is considered as unreachable and marked as suspected. A low threshold allows to
detect member crashes/failures faster but can generate more mistakes and cause
wrong member suspicions. A high threshold generates fewer mistakes but is slower
to detect actual crashes/failures.
+
`phi = 1` means likeliness that we will make a mistake is about `10%`. The likeliness
is about `1%` with `phi = 2`, `0.1%` with `phi = 3` and so on. Default phi threshold is 10.
+
* `hazelcast.heartbeat.phiaccrual.failuredetector.sample.size`: Number of samples
to keep for history. Its default value is 200.
* `hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis`: Minimum
standard deviation to use for the normal distribution used when calculating phi.
Too low standard deviation might result in too much sensitivity.

To use _Phi Accrual Failure Detector_, configuration property
`hazelcast.heartbeat.failuredetector.type` should be set to `"phi-accrual"`.

**Declarative Configuration:**

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <properties>
        <property name="hazelcast.heartbeat.failuredetector.type">phi-accrual</property>
        <property name="hazelcast.heartbeat.interval.seconds">1</property>
        <property name="hazelcast.max.no.heartbeat.seconds">60</property>
        <property name="hazelcast.heartbeat.phiaccrual.failuredetector.threshold">10</property>
        <property name="hazelcast.heartbeat.phiaccrual.failuredetector.sample.size">200</property>
        <property name="hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis">100</property>
    </properties>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  properties:
    hazelcast.heartbeat.failuredetector.type: phi-accrual
    hazelcast.heartbeat.interval.seconds: 1
    hazelcast.max.no.heartbeat.seconds: 60
    hazelcast.heartbeat.phiaccrual.failuredetector.sample.size: 200
    hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis: 100
----

**Programmatic Configuration:**

[source,java]
----
Config config = ...;
config.setProperty("hazelcast.heartbeat.failuredetector.type", "phi-accrual");
config.setProperty("hazelcast.heartbeat.interval.seconds", "1");
config.setProperty("hazelcast.max.no.heartbeat.seconds", "60");
config.setProperty("hazelcast.heartbeat.phiaccrual.failuredetector.threshold", "10");
config.setProperty("hazelcast.heartbeat.phiaccrual.failuredetector.sample.size", "200");
config.setProperty("hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis", "100");
[...]
----

[[ping-failure-detector]]
==== Ping Failure Detector

The Ping Failure Detector may be configured in addition to one of Deadline and
Phi Accrual Failure Detectors. It operates at Layer 3 of the OSI protocol and
provides much quicker and more deterministic detection of hardware and other
lower level events. This detector may be configured to perform an extra check
after a member is suspected by one of the other detectors, or it can work in
parallel, which is the default. This way hardware and network level issues are
detected more quickly.

This failure detector is based on `InetAddress.isReachable()`.
When the JVM process has enough permissions to create RAW sockets, the
implementation chooses to rely on ICMP Echo requests. This is preferred.

If there are not enough permissions, it can be configured to fallback on
attempting a TCP Echo on port 7. In the latter case, both a successful
connection or an explicit rejection is treated as "Host is Reachable".
Or, it can be forced to use only RAW sockets. This is not preferred as
each call creates a heavy weight socket and moreover the Echo service is
typically disabled.

For the Ping Failure Detector to rely **only** on ICMP Echo requests,
there are some criteria that need to be met.

[[requirements-and-linuxunix-configuration]]
===== Requirements and Linux/Unix Configuration

* **Supported OS: as of Java 1.8 only Linux/Unix environments are supported**.
This detector relies on ICMP, i.e., the protocol behind the `ping` command.
It tries to issue the ping attempts periodically, and their responses are used
to determine the reachability of the remote member. However, you cannot simply
create an ICMP Echo Request because these type of packets do not rely on any of
the preexisting transport protocols such as TCP. In order to create such a request,
you must have the privileges to create RAW sockets (see link:https://linux.die.net/man/7/raw[https://linux.die.net/man/7/raw^]).
Most operating systems allow this to the root users, however Unix based ones
are more flexible and allow the use of custom privileges per process
instead of requiring root access. Therefore, this detector is supported only on Linux.
* **The Java executable must have the `cap_net_raw` capability.** As described in
the above requirement, on Linux, you have the ability to define extra capabilities
to a single process, which would allow the process to interact with the RAW sockets.
This interaction is achieved via the capability `cap_net_raw`
(see link:https://linux.die.net/man/7/capabilities[https://linux.die.net/man/7/capabilities^]).
To enable this capability run the following command:
+
`sudo setcap cap_net_raw=+ep <JDK_HOME>/jre/bin/java`
+
* **When running with custom capabilities, the dynamic linker on Linux rejects
loading the libs from untrusted paths.** Since you have now `cap_net_raw` as a
custom capability for a process, it becomes suspicious to the dynamic linker
and throws an error: `java: error while loading shared libraries: libjli.so:
cannot open shared object file: No such file or directory`
** To overcome this rejection, the `<JDK_HOME>/jre/lib/amd64/jli/` path needs
to be added in the `ld.conf`. Run the following command to do this:
`echo "<JDK_HOME>/jre/lib/amd64/jli/" >> /etc/ld.so.conf.d/java.conf && sudo ldconfig`
* **ICMP Echo Requests must not be blocked by the receiving hosts.**
`/proc/sys/net/ipv4/icmp_echo_ignore_all` set to `0`.
Run the following command:
+
`echo 0 > /proc/sys/net/ipv4/icmp_echo_ignore_all`

If any of the above criteria isn't met, then the `isReachable`
always falls back on TCP Echo attempts on port 7.

To be able to use the Ping Failure Detector, you can configure it
using the `icmp` element in your Hazelcast IMDG declarative configuration
file, e.g., `hazelcast.xml`. An example is shown below:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    <network>
    ...
        <failure-detector>
            <icmp enabled="true">
                <timeout-milliseconds>1000</timeout-milliseconds>
                <fail-fast-on-startup>true</fail-fast-on-startup>
                <interval-milliseconds>1000</interval-milliseconds>
                <max-attempts>3</max-attempts>
                <parallel-mode>true</parallel-mode>
                <ttl>0</ttl>
            </icmp>
        </failure-detector>
    </network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  network:
    failure-detector:
      icmp:
        enabled: true
        timeout-milliseconds: 1000
        fail-fast-on-startup: true
        interval-milliseconds: 1000
        max-attempts: 3
        parallel-mode: true
        ttl: 0
----

The following are the element and attribute descriptions:

* `enabled`: Specifies whether the legacy ICMP detection mode is enabled; works
cooperatively with the existing failure detector and only kicks-in after
a pre-defined period has passed with no heartbeats from a member.
Its default value is `false`.
* `parallel-mode`: Specifies whether the parallel ping detector is enabled;
works separately from the other detectors. Its default value is `true`.
* `timeout-milliseconds`: Number of milliseconds until a ping attempt
is considered failed if there was no reply. Its default value is `1000` milliseconds.
* `max-attempts`: Maximum number of ping attempts before
the member/node gets suspected by the detector. Its default value is `2`.
* `interval-milliseconds`: Interval, in milliseconds, between each ping
attempt. 1000ms (1 sec) is also the minimum interval allowed.
Its default value is `1000` milliseconds.
* `ttl`: Maximum number of hops the packets should
go through. Its default value is `0`.
* `fail-fast-on-startup`: Specifies whether the cluster member fails to start
if it is unable to action an ICMP ping command when ICMP is enabled. Failure
is usually due to OS level restrictions.

In the above example configuration, the Ping detector attempts 3 pings, one every second and
waits up to 1 second for each to complete. If after 3 seconds, there was no successful
ping, the member gets suspected.

To enforce the <<requirements-and-linuxunix-configuration, Requirements>>, the property
`hazelcast.icmp.echo.fail.fast.on.startup` can also be set to `true`, in which case,
if any of the requirements isn't met, Hazelcast fails to start.

Below is a summary table of all possible configuration combinations
of the ping failure detector.

[cols="1,1,1,3,2,1,1"]
.Ping Failure Detector Possible Configuration Combinations
|===
| ICMP | Parallel | Fail-Fast | Description | Linux | Windows | macOS

| false
| false
| false
| Completely disabled                                                                                                                                                                                                         | N/A
| N/A
| N/A

| true
| false
| false
| Legacy ping mode. This works hand-to-hand with the OSI Layer 7 failure
detector (see. phi or deadline in the sections above). Ping in this mode
only kicks in after a period when there are no heartbeats received, in which
case the remote Hazelcast member is pinged up to a configurable count of attempts.
If all those attempts fail, the member gets suspected. You can configure this
attempt count using the `max-attempts` configuration element listed above.
| Supported  ICMP Echo if available - Falls back on TCP Echo on port 7
| Supported  TCP Echo on port 7
| Supported ICMP Echo if available - Falls back on TCP Echo on port 7

| true
| true
| false
| Parallel ping detector, works in parallel with the configured failure detector.
Checks periodically if members are live (OSI Layer 3) and suspects them immediately,
regardless of the other detectors.
| Supported  ICMP Echo if available - Falls back on TCP Echo on port 7
| Supported  TCP Echo on port 7
| Supported  ICMP Echo if available - Falls back on TCP Echo on port 7

| true
| true
| true
| Parallel ping detector, works in parallel with the configured failure detector.
Checks periodically if members are live (OSI Layer 3) and suspects them immediately,
regardless of the other detectors.
| Supported - Requires OS Configuration  Enforcing ICMP Echo if available -
No start up if not available
| Not Supported
| Not Supported - Requires root privileges
|===

=== Advanced Network Configuration

With the default configuration, Hazelcast members use a single server socket for all kinds
of connections: cluster members, Hazelcast clients implementing the Open Binary Client
Protocol and HTTP protocol clients connect to a single server socket that handles all the protocols.

You can also configure the Hazelcast members with
separate server sockets using a different network configuration for different protocols.
This configuration scheme allows more flexibility when deploying Hazelcast as described
in the following cases:

* For security, it is possible to bind the member protocol server socket on a protected
internal network interface, while the client connections can be established on another
network interface accessible by the Hazelcast clients.
* Different kinds of network connections can be established with different socket options.
For example varying send/receive window size to optimize the network usage, TLS for
connections over WAN while member-to-member connections may remain unencrypted, etc.

In the following example we introduce the advanced network configuration for a
member to listen for member-to-member connections on the default port `5701` while
listening for client connections on the port `9090`:

[source,java]
----
include::{javasource}/settingupclusters/AdvancedNetworkConfig.java[tag=advNetConf]
----

Running this example prints something similar to the following output,
indicating that the member listens for the specified protocols on the respective configured ports:

```
{EndpointQualifier{type='CLIENT'}=[10.212.134.156]:9090, EndpointQualifier{type='MEMBER'}=[10.212.134.156]:5701}
```

The following is the equivalent declarative configuration:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <advanced-network enabled="true">
        <member-server-socket-endpoint-config>
            <port>5701</port>
        </member-server-socket-endpoint-config>
        <client-server-socket-endpoint-config>
            <port>9090</port>
        </client-server-socket-endpoint-config>
    </advanced-network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  advanced-network:
    enabled: true
    member-server-socket-endpoint-config:
      port:
        - 5701
    client-server-socket-endpoint-config:
      port:
        - 9090
----

==== Setting Up Cluster Members for Advanced Network Configuration

Advanced network configuration and single-socket network configuration are
mutually exclusive: either an enabled `AdvancedNetworkConfig` or the `NetworkConfig`
object is used to configure a member's networking, including the joiner, discovery,
failure detectors, etc. as described in the previous sections of this chapter.

You cannot define both elements in the declarative configuration, i.e., the `network`
and `advanced-network` elements cannot be configured at the same time. In the
programmatic configuration, an enabled `AdvancedNetworkConfig` takes precedence over
the `NetworkConfig`. `AdvancedNetworkConfig` is disabled by default, therefore the
unisocket member configuration under `NetworkConfig` is used in the default case.

When using the advanced network configuration, the following configurations are defined
member-wide:

* Joiner and cluster discovery (Multicast, TCP/IP, AWS, Azure, GCP, Kubernetes, Eureka, etc.)
* `MemberAddressProvider` configuration
* Failure detector configuration

In addition to the above, the advanced network configuration allows the
configuration of multiple endpoints: each endpoint configuration applies for a
specific protocol, e.g., `MEMBER` and `CLIENT`. An additional optional identifier
can be configured to separate the configuration of multiple `WAN` protocol endpoints.

The supported protocols are as follows:

* `MEMBER`: A member server socket is required for Hazelcast to operate. The default
advanced network configuration defines a member endpoint configuration listening on
port 5701 (same as the single-socket Hazelcast member configuration).
* `CLIENT`: A single server socket handling the Hazelcast Open Binary Client Protocol
can be optionally configured. If no such endpoint is configured, then the clients will
not be able to connect to the Hazelcast member.
* `REST`: A REST server socket is optional.
* `MEMCACHE`: When accessing a Hazelcast cluster over the Memcache text protocol, an
endpoint listening to `MEMCACHE` protocol must be defined.
* `WAN`: Multiple WAN endpoint configurations can be defined to determine the network
settings of outgoing connections (from the members of a source cluster to the target
WAN cluster members) or to establish server sockets on which a target WAN member can
listen for the incoming connections from the source cluster.

==== Server Socket Endpoint Configuration

The server socket endpoint configuration is common for all protocols. The elements
comprising a server socket endpoint configuration are identical to their single-socket
network configuration counterparts.

The following declarative configuration example includes all the common server
socket endpoint elements:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
   ...
   <advanced-network enabled="true">
       <member-server-socket-endpoint-config>
           <port auto-increment="true" port-count="100">5701</port>
           <outbound-ports>
               <ports>33000-35000</ports>
               <ports>37000,37001,37002,37003</ports>
               <ports>38000,38500-38600</ports>
           </outbound-ports>
           <interfaces enabled="true">
               <interface>10.10.1.*</interface>
           </interfaces>
           <ssl enabled="true">
               <factory-class-name>com.hazelcast.examples.MySSLContextFactory</factory-class-name>
               <properties>
                   <property name="foo">bar</property>
               </properties>
           </ssl>
           <symmetric-encryption>
               <algorithm>ALGO</algorithm>
               <salt>SALT</salt>
               <password>PASS</password>
               <iteration-count>10000</iteration-count>
           </symmetric-encryption>
           <socket-interceptor enabled="true">
               <class-name>com.hazelcast.examples.MySocketInterceptor</class-name>
               <properties>
                   <property name="foo">bar</property>
               </properties>
           </socket-interceptor>
           <socket-options>
               <buffer-direct>true</buffer-direct>
               <tcp-no-delay>true</tcp-no-delay>
               <keep-alive>true</keep-alive>
               <connect-timeout-seconds>64</connect-timeout-seconds>
               <send-buffer-size-kb>25</send-buffer-size-kb>
               <receive-buffer-size-kb>33</receive-buffer-size-kb>
               <linger-seconds>99</linger-seconds>
           </socket-options>
           <public-address>dummy</public-address>
           <reuse-address>true</reuse-address>
        </member-server-socket-endpoint-config>
    </advanced-network>
    ...
</hazelcast>

----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  advanced-network
    enabled: true
    member-server-socket-endpoint-config:
    port:
      auto-increment: true
      port-count: 100
      port: 5701
    outbound-ports:
      - 33000-35000
      - 37000,37001,37002,37003
      - 38000,38500-38600
    interfaces:
      enabled: true
      interfaces:
        - 10.10.1.*
    ssl:
      enabled: true
      factory-class-name: com.hazelcast.examples.MySSLContextFactory
      properties:
        foo: bar
    symmetric-encryption:
      algorithm: ALGO
      salt: SALT
      password: PASS
      iteration-count: 10000
    socket-interceptor:
      enabled: true
      class-name: com.hazelcast.examples.MySocketInterceptor
      properties:
        foo: bar
    socket-options:
      buffer-direct: true
      tcp-no-delay: true
      keep-alive: true
      connect-timeout-seconds: 64
      send-buffer-size-kb: 25
      receive-buffer-size-kb: 33
      linger-seconds: 99
    public-address: dummy
    reuse-address: true
----

When using the declarative configuration, specific element names introduce the
server socket endpoint configuration for each protocol:

* `member-server-socket-endpoint-config` for `MEMBER` protocol
* `client-server-socket-endpoint-config` for `CLIENT` protocol
* `rest-server-socket-endpoint-config` for `REST` endpoint
* `memcache-server-socket-endpoint-config` for `MEMCACHE` endpoint
* `wan-server-socket-endpoint-config` for `WAN` endpoints

When using the programmatic configuration, corresponding methods set the
respective server socket endpoint configuration:

[source,java]
----
include::{javasource}/settingupclusters/AdvancedNetworkConfig.java[tag=memberServerSocket]
----

==== Setting Up REST Server Socket Endpoint Configuration

In addition to the common server socket configuration described above, the REST
endpoint configuration includes certain additional elements which are used to
enable/disable the REST functionality groups.

[source,java]
----
include::{javasource}/settingupclusters/AdvancedNetworkConfig.java[tag=restServerSocket]
----

The following is the equivalent declarative configuration:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <advanced-network enabled="true">
        <rest-server-socket-endpoint-config>
            <port auto-increment="false">8080</port>
            <endpoint-groups>
                <endpoint-group name="WAN" enabled="true"/>
                <endpoint-group name="CLUSTER_READ" enabled="true"/>
                <endpoint-group name="HEALTH_CHECK" enabled="true"/>
            </endpoint-groups>
        </rest-server-socket-endpoint-config>
    </advanced-network>
    ...
</hazelcast>

----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  advanced-network:
    enabled: true
    rest-server-socket-endpoint-config:
      port:
        auto-increment: false
        port: 8080
      endpoint-groups:
        WAN:
          enabled: true
        CLUSTER_READ:
          enabled: true
        HEALTH_CHECK:
          enabled: true
----

==== Setting Up WAN Endpoints Configuration

Multiple WAN endpoint configurations can be defined to configure the outgoing
connections and server sockets, depending on the role of the member in the WAN
replication. The configuration examples are provided in the following sections for
both active and passive side of the WAN replication.

===== Configuring the WAN Active Side

The members on the active cluster initiate connections to the target cluster members,
so there is no need to create a server socket. A plain `EndpointConfig` is created that
supplies the configuration for the client side of connections that the active members
will create:

[source,java]
----
include::{javasource}/settingupclusters/AdvancedNetworkConfig.java[tag=wanActiveEndpoint]
----

The following is the equivalent declarative configuration:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <advanced-network enabled="true">
        <wan-endpoint-config name="tokyo">
            <ssl enabled="true">
                <factory-class-name>com.hazelcast.examples.MySSLContextFactory</factory-class-name>
                <properties>
                    <property name="endpoints">tokyo.example.com:11010</property>
                </properties>
            </ssl>
        </wan-endpoint-config>
    </advanced-network>
    ...
    <wan-replication name="replicate-to-tokyo">
        <batch-publisher>
            <cluster-name>clusterB</cluster-name>
            <target-endpoints>...</target-endpoints>
        </batch-publisher>
    </wan-replication>
    ...
    <map name="customer">
        <wan-replication-ref name="replicate-to-tokyo">
            <merge-policy>...</merge-policy>
        </wan-replication-ref>
    </map>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  advanced-network:
    enabled: true
    wan-endpoint-config:
      endpoint-tokyo:
        ssl:
          enabled: true
          factory-class-name: com.hazelcast.examples.MySSLContextFactory
          properties:
            endpoints: tokyo.example.com:11010
    wan-replication:
      replicate-to-tokyo:
        batch-publisher:
          cluster-name: clusterB<
          target-endpoints: ...
    map:
      customer:
        wan-replication-ref:
          replicate-to-tokyo:
            merge-policy-class-name: ...
----

The `wan-endpoint-config` element contains the same sub-elements as the
`member-server-socket-endpoint-config` element described above except `port`,
`public-address` and `reuse-address`

===== Configuring the WAN Passive Side

On the passive cluster, a server socket is configured on the members to listen
for the incoming WAN connections, matching the network configuration (SSL configuration,
etc.) configured on the active side of the WAN replication.

[source,java]
----
include::{javasource}/settingupclusters/AdvancedNetworkConfig.java[tag=wanPassiveEndpoint]
----

The following is the equivalent declarative configuration:

[source,xml,indent=0,subs="verbatim,attributes",role="primary"]
.XML
----
<hazelcast>
    ...
    <advanced-network enabled="true">
        <wan-server-socket-endpoint-config name="tokyo">
            <port auto-increment="false">11010</port>
            <ssl enabled="true">
                <factory-class-name>com.hazelcast.examples.MySSLContextFactory</factory-class-name>
                <properties>
                    <property name="foo">bar</property>
                </properties>
            </ssl>
        </wan-server-socket-endpoint-config>
    </advanced-network>
    ...
</hazelcast>
----

[source,yml,indent=0,subs="verbatim,attributes",role="secondary"]
.YAML
----
hazelcast:
  advanced-network:
    enabled: true
    wan-server-socket-endpoint-config:
      tokyo:
        port:
          auto-increment: false
          port: 11010
        ssl:
          enabled: true
          factory-class-name: com.hazelcast.examples.MySSLContextFactory
        properties:
          foo: bar
----

==== Advanced Network Configuration FAQ

[qanda]
Can I multiplex protocols on a single advanced network endpoint? For example, can I use a single server socket to listen for `MEMBER` and `CLIENT` protocols?::
    No, each endpoint configuration that defines a server socket must bind to a different socket address.
Can I mix unisocket and advanced network members in the same cluster?::
    No, the results will be undefined.
Can I configure multiple server socket endpoints for the same protocol?::
    You can only configure multiple server socket endpoints for `WAN` protocol. For other protocols (`MEMBER`, `CLIENT`, `REST`, `MEMCACHE`), a single server socket can be configured.
